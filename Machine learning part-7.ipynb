{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPpKoO6GHcoJ4ur0WdUAeW4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Logistic Regression Theory Questions and Answers\n","\n","1. What is Logistic Regression, and how does it differ from Linear Regression?\n","Answer: Logistic Regression is a classification algorithm used to predict the probability of a categorical dependent variable. Unlike Linear Regression that predicts continuous outcomes, Logistic Regression predicts probabilities by applying the logistic (sigmoid) function to the linear combination of inputs.\n","\n","2. What is the mathematical equation of Logistic Regression?\n","Answer: The logistic regression model estimates the probability p as:\n","p = 1 / (1 + e^-(β0 + β1x1 + β2x2 + ... + βnxn))\n","\n","3. Why do we use the Sigmoid function in Logistic Regression?\n","Answer: The Sigmoid function maps any real-valued number into the (0,1) interval, which is ideal for modeling probabilities.\n","\n","4. What is the cost function of Logistic Regression?\n","Answer: The cost function is the Log Loss (Binary Cross-Entropy), which penalizes wrong predictions more when the confidence is higher.\n","\n","5. What is Regularization in Logistic Regression? Why is it needed?\n","Answer: Regularization adds a penalty term to the loss function to avoid overfitting by discouraging large coefficients.\n","\n","6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n","Answer: Lasso (L1) adds absolute value penalties, leading to sparse models; Ridge (L2) adds squared penalties, leading to small but non-zero coefficients; Elastic Net combines both penalties.\n","\n","7. When should we use Elastic Net instead of Lasso or Ridge?\n","Answer: Elastic Net is useful when there are multiple correlated features. It balances L1 and L2 penalties.\n","\n","8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n","Answer: Higher λ increases penalty strength, reducing model complexity and variance but increasing bias.\n","\n","9. What are the key assumptions of Logistic Regression?\n","Answer: Assumes linearity between independent variables and log-odds, no multicollinearity, and independence of observations.\n","\n","10. What are some alternatives to Logistic Regression for classification tasks?\n","Answer: Alternatives include Decision Trees, Random Forests, SVM, Neural Networks, and Naive Bayes.\n","\n","11. What are Classification Evaluation Metrics?\n","Answer: Accuracy, Precision, Recall, F1-Score, ROC-AUC, Confusion Matrix.\n","\n","12. How does class imbalance affect Logistic Regression?\n","Answer: It may bias the model toward the majority class, reducing recall on the minority class.\n","\n","13. What is Hyperparameter Tuning in Logistic Regression?\n","Answer: Process of selecting optimal parameters like regularization strength (C), penalty type, and solver to improve performance.\n","\n","14. What are different solvers in Logistic Regression? Which one should be used?\n","Answer: Solvers include liblinear, saga, lbfgs, newton-cg, and sag. Choice depends on dataset size and penalty used.\n","\n","15. How is Logistic Regression extended for multiclass classification?\n","Answer: By using One-vs-Rest (OvR) or Softmax (Multinomial) regression.\n","\n","16. What are the advantages and disadvantages of Logistic Regression?\n","Answer: Advantages: simplicity, interpretability, efficiency. Disadvantages: limited to linear decision boundaries, struggles with complex patterns.\n","\n","17. What are some use cases of Logistic Regression?\n","Answer: Credit scoring, disease diagnosis, spam detection, marketing response prediction.\n","\n","18. What is the difference between Softmax Regression and Logistic Regression?\n","Answer: Softmax handles multiple classes by generalizing Logistic Regression, which is binary.\n","\n","19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n","Answer: OvR is simpler and works well with many classes, Softmax models all classes simultaneously and can be more accurate.\n","\n","20. How do we interpret coefficients in Logistic Regression?\n","Answer: Coefficients indicate the change in log-odds of the outcome per unit change in the predictor.\n","\n"],"metadata":{"id":"t8q1v-_KlnNP"}},{"cell_type":"code","source":["# Logistic Regression Practical Examples with Question Numbers\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV, cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, matthews_corrcoef, precision_recall_curve\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","\n","# BC Write a Python program that loads a dataset, splits it, applies Logistic Regression, and prints accuracy\n","def q1_basic_logistic_regression():\n","    X, y = load_breast_cancer(return_X_y=True)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","    clf = LogisticRegression(max_iter=1000)\n","    clf.fit(X_train, y_train)\n","    y_pred = clf.predict(X_test)\n","    print(\"Q1 - Accuracy:\", accuracy_score(y_test, y_pred))\n","\n","# 'C Write a Python program to apply L1 regularization (Lasso) and print accuracy\n","def q2_l1_regularization():\n","    X, y = load_breast_cancer(return_X_y=True)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","    clf = LogisticRegression(penalty='l1', solver='saga', max_iter=1000)\n","    clf.fit(X_train, y_train)\n","    print(\"Q2 - L1 Regularization Accuracy:\", clf.score(X_test, y_test))\n","\n","# $C Write a Python program to train Logistic Regression with L2 regularization and print accuracy and coefficients\n","def q3_l2_regularization():\n","    X, y = load_breast_cancer(return_X_y=True)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","    clf = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n","    clf.fit(X_train, y_train)\n","    print(\"Q3 - L2 Regularization Accuracy:\", clf.score(X_test, y_test))\n","    print(\"Coefficients:\", clf.coef_)\n","\n","# #C Write a Python program to train Logistic Regression with Elastic Net Regularization\n","def q4_elastic_net_regularization():\n","    X, y = load_breast_cancer(return_X_y=True)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","    clf = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n","    clf.fit(X_train, y_train)\n","    print(\"Q4 - Elastic Net Accuracy:\", clf.score(X_test, y_test))\n","\n","# \u001fC Logistic Regression model for multiclass classification (One-vs-Rest)\n","def q5_multiclass_ovr():\n","    from sklearn.datasets import load_iris\n","    X, y = load_iris(return_X_y=True)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","    clf = LogisticRegression(multi_class='ovr', max_iter=1000)\n","    clf.fit(X_train, y_train)\n","    print(\"Q5 - OvR Multiclass Accuracy:\", clf.score(X_test, y_test))\n","\n","# \"C Apply GridSearchCV to tune hyperparameters of Logistic Regression\n","def q6_gridsearchcv_tuning():\n","    X, y = load_breast_cancer(return_X_y=True)\n","    param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n","    clf = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n","    clf.fit(X, y)\n","    print(\"Q6 - Best Params:\", clf.best_params_)\n","    print(\"Q6 - Best Accuracy:\", clf.best_score_)\n","\n","# \u001bC Stratified K-Fold Cross-Validation evaluation\n","def q7_stratified_kfold_cv():\n","    X, y = load_breast_cancer(return_X_y=True)\n","    clf = LogisticRegression(max_iter=1000)\n","    skf = StratifiedKFold(n_splits=5)\n","    scores = cross_val_score(clf, X, y, cv=skf)\n","    print(\"Q7 - Stratified K-Fold CV Accuracy:\", scores.mean())\n","\n","# \u0018C Load CSV dataset, apply Logistic Regression, and evaluate accuracy (dummy example)\n","def q8_logistic_regression_csv():\n","    # Example: Using breast cancer dataset as CSV-like\n","    data = load_breast_cancer()\n","    df = pd.DataFrame(data.data, columns=data.feature_names)\n","    df['target'] = data.target\n","    X = df.drop('target', axis=1)\n","    y = df['target']\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","    clf = LogisticRegression(max_iter=1000)\n","    clf.fit(X_train, y_train)\n","    print(\"Q8 - Accuracy on CSV dataset:\", clf.score(X_test, y_test))\n","\n","\n","if __name__ == \"__main__\":\n","    q1_basic_logistic_regression()\n","    q2_l1_regularization()\n","    q3_l2_regularization()\n","    q4_elastic_net_regularization()\n","    q5_multiclass_ovr()\n","    q6_gridsearchcv_tuning()\n","    q7_stratified_kfold_cv()\n","    q8_logistic_regression_csv()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BXmM4EYlon5","executionInfo":{"status":"ok","timestamp":1748833378336,"user_tz":-330,"elapsed":44667,"user":{"displayName":"prem sharma","userId":"08916668901930045136"}},"outputId":"eb28a8c2-b4de-40cf-e5eb-eea32db78343"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Q1 - Accuracy: 0.958041958041958\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Q2 - L1 Regularization Accuracy: 0.958041958041958\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Q3 - L2 Regularization Accuracy: 0.958041958041958\n","Coefficients: [[ 2.15532225  0.18714602 -0.24416747  0.00572091 -0.1497949  -0.37285194\n","  -0.68842716 -0.40105696 -0.21745825 -0.02431973 -0.10238349  1.21390283\n","   0.02970182 -0.10397078 -0.0207384   0.01710296 -0.04370813 -0.04714993\n","  -0.04576097  0.00424877  1.18521282 -0.41575137 -0.02673249 -0.02611631\n","  -0.28772255 -0.93912745 -1.60622852 -0.67726337 -0.78534399 -0.089987  ]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Q4 - Elastic Net Accuracy: 0.958041958041958\n","Q5 - OvR Multiclass Accuracy: 0.9736842105263158\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Q6 - Best Params: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n","Q6 - Best Accuracy: 0.9578326346840551\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"stream","name":"stdout","text":["Q7 - Stratified K-Fold CV Accuracy: 0.9525694767893185\n","Q8 - Accuracy on CSV dataset: 0.958041958041958\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]}]}